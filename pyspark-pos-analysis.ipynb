{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c056ee16",
   "metadata": {},
   "source": [
    "# PySpark Part of Speech (POS) analysis\n",
    "Text taken from [Reuters](https://www.reuters.com/business/finance/banks-beware-outsiders-are-cracking-code-finance-2021-09-17/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddbef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cad46f10-a273-4698-9657-f66af586d088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc213b0-7387-41f6-bb14-add0fb94791a",
   "metadata": {},
   "source": [
    "### NLTK packages are downloaded\n",
    "This includes an \"universal_tagset\" which will help categorizing in POS all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b5d92ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mateo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mateo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\mateo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462a059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point for working with RDD\n",
    "sc = SparkContext(appName = \"pyspark-pos-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72d6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a text file\n",
    "rdd_reuters = sc.textFile(\"./data/reuters.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa41c11-74d3-454e-ab93-031bd7b39227",
   "metadata": {},
   "source": [
    "### Verifying results\n",
    "First we will count the results on the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c6d905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_reuters.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c835e40-a4b1-47d2-99cc-03b53acea2f9",
   "metadata": {},
   "source": [
    "Then, we can use a \".take(5)\" command in order to verify how the data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91224721-c366-4463-8fa0-1b8ff971c89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Banks beware, Amazon and Walmart are cracking the code for finance',\n",
       " '',\n",
       " 'LONDON, Sept 17 (Reuters) - Anyone can be a banker these days, you just need the right code.',\n",
       " '',\n",
       " 'Global brands from Mercedes and Amazon (AMZN.O) to IKEA and Walmart (WMT.N) are cutting out the traditional financial middleman and plugging in software from tech startups to offer customers everything from banking and credit to insurance.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_reuters.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869313e8-1d5e-432d-9be9-fe79a1d2923c",
   "metadata": {},
   "source": [
    "## Splitting words from text and putting them on a flat structure\n",
    "This result is stored to be used as a list. Taking its first 15 elements, we can see this object as we can see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7ad3e22-f7aa-4fb9-af1b-4176e692ead8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Banks',\n",
       " 'beware',\n",
       " ',',\n",
       " 'Amazon',\n",
       " 'and',\n",
       " 'Walmart',\n",
       " 'are',\n",
       " 'cracking',\n",
       " 'the',\n",
       " 'code',\n",
       " 'for',\n",
       " 'finance',\n",
       " 'LONDON',\n",
       " ',',\n",
       " 'Sept']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = rdd_reuters.flatMap(lambda x: word_tokenize(x))\n",
    "words.take(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86d1bc5-3faa-40e5-817c-f3657370ed7c",
   "metadata": {},
   "source": [
    "### Using NLTK to analyze POS on the splitted text\n",
    "First, we use the \"pos_tag()\" method to create pairs between the words and their respective Part of Speech (POS). This will use the previously downloaded \"universal\" tagset, wich will use only the desired categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc6523c5-e9b2-4eeb-961a-4009fdf59f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Banks', 'NOUN')\n",
      "('beware', 'NOUN')\n",
      "(',', '.')\n",
      "('Amazon', 'NOUN')\n",
      "('and', 'CONJ')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words = nltk.pos_tag(words.collect(), tagset='universal')\n",
    "# This will print only 5 of the obtained results\n",
    "[print(a) for a in tagged_words[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ed648-027c-426b-b53d-5a7c94be9b70",
   "metadata": {},
   "source": [
    "With this list, now we can use NTLK \"FreqDist()\" and \"most_common()\" methods in order to count and generate another list with the results of each POS tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e55694ab-de49-4524-b69f-c770d3d2a454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 422),\n",
       " ('VERB', 248),\n",
       " ('.', 209),\n",
       " ('ADP', 143),\n",
       " ('ADJ', 95),\n",
       " ('DET', 91),\n",
       " ('ADV', 61),\n",
       " ('PRT', 59),\n",
       " ('PRON', 56),\n",
       " ('CONJ', 45),\n",
       " ('NUM', 35)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tagged_words)\n",
    "tag_fd.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84fc6cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
